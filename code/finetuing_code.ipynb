{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments,EsmForSequenceClassification, AdamW,EsmTokenizer\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune import CLIReporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is on \n",
      "God SpeeD üèéÔ∏èüèéÔ∏èüèéÔ∏èüèéÔ∏è\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda is on\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/home/ubuntu/work/data/new/mini/balanced/train_data4.csv\")\n",
    "test_data = pd.read_csv(\"/home/ubuntu/work/data/new/mini/balanced/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", do_lower_case=False)\n",
    "model = EsmForSequenceClassification.from_pretrained(\"/home/ubuntu/work/codes/multi fine tuning4/tune4/best_model4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processor(Dataset):\n",
    "    def __init__(self, df, tokenizer_name=\"facebook/esm2_t6_8M_UR50D\", max_len=24):\n",
    "        self.tokenizer = EsmTokenizer.from_pretrained(tokenizer_name, do_lower_case=False)\n",
    "        self.max_len = max_len\n",
    "        self.seqs, self.labels = self.get_seqs_labels(df)\n",
    "\n",
    "    def get_seqs_labels(self, df):\n",
    "        seqs = list(df['seq'])\n",
    "        labels = list(df['type'].astype(int))\n",
    "        return seqs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = \" \".join(\"\".join(self.seqs[idx].split()))\n",
    "        seq_ids = self.tokenizer(seq, truncation=True, padding='max_length', max_length=self.max_len)\n",
    "        sample = {key: torch.tensor(val) for key, val in seq_ids.items()}\n",
    "        sample['labels'] = torch.tensor(self.labels[idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return  EsmForSequenceClassification.from_pretrained(\"/home/ubuntu/work/codes/multi fine tuning4/tune4/best_model4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata  = processor(train_data)\n",
    "evaldata = processor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)  # Predicted classes\n",
    "    probs = pred.predictions[:, 1]       # Probabilities for positive class\n",
    "\n",
    "    # Calculate basic metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    # Calculate confusion matrix for specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Calculate AUC-ROC score\n",
    "    auc = roc_auc_score(labels, probs)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'auc_roc': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/sathdeep/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1250e271964e7b9751a25fb618e35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb0866f9e584ed893cf5eef80df70d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46441447734832764, 'eval_accuracy': 0.85, 'eval_f1': 0.8421052631578947, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8, 'eval_specificity': 0.9, 'eval_auc_roc': 0.9036111111111111, 'eval_runtime': 0.0799, 'eval_samples_per_second': 1500.963, 'eval_steps_per_second': 187.62, 'epoch': 0.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b80837ea63472dae35b3a107561430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46588438749313354, 'eval_accuracy': 0.85, 'eval_f1': 0.8421052631578947, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8, 'eval_specificity': 0.9, 'eval_auc_roc': 0.9019444444444444, 'eval_runtime': 0.0529, 'eval_samples_per_second': 2269.512, 'eval_steps_per_second': 283.689, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ca9b0d71964f6291239727b76522f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4668828248977661, 'eval_accuracy': 0.8416666666666667, 'eval_f1': 0.831858407079646, 'eval_precision': 0.8867924528301887, 'eval_recall': 0.7833333333333333, 'eval_specificity': 0.9, 'eval_auc_roc': 0.9034722222222221, 'eval_runtime': 0.0506, 'eval_samples_per_second': 2370.567, 'eval_steps_per_second': 296.321, 'epoch': 2.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1510c43fed844aff88aaa4ea5041b44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4693514406681061, 'eval_accuracy': 0.8333333333333334, 'eval_f1': 0.8214285714285714, 'eval_precision': 0.8846153846153846, 'eval_recall': 0.7666666666666667, 'eval_specificity': 0.9, 'eval_auc_roc': 0.9036111111111111, 'eval_runtime': 0.0513, 'eval_samples_per_second': 2340.8, 'eval_steps_per_second': 292.6, 'epoch': 3.64}\n",
      "{'train_runtime': 1.3578, 'train_samples_per_second': 1259.371, 'train_steps_per_second': 7.365, 'train_loss': 0.2322521686553955, 'epoch': 3.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8577d2856a414a75957063e2351c37f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "eval_loss: 0.4693514406681061\n",
      "eval_accuracy: 0.8333333333333334\n",
      "eval_f1: 0.8214285714285714\n",
      "eval_precision: 0.8846153846153846\n",
      "eval_recall: 0.7666666666666667\n",
      "eval_specificity: 0.9\n",
      "eval_auc_roc: 0.9036111111111111\n",
      "eval_runtime: 0.0645\n",
      "eval_samples_per_second: 1859.026\n",
      "eval_steps_per_second: 232.378\n",
      "epoch: 3.6363636363636362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the hyperparameters for training (from hyperparameter search)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                    # Output directory to save the model\n",
    "    num_train_epochs=5,                        # Number of training epochs\n",
    "    learning_rate=  2.1430509048903236e-05,                        # Learning rate for the optimizer\n",
    "    per_device_train_batch_size=16,            # Batch size per device during training\n",
    "    warmup_steps=500,                          # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay= 0.13684509966496455,                         # Strength of weight decay\n",
    "    logging_dir='./logs',                      # Directory for storing logs\n",
    "    logging_steps=100,                         # Frequency of logging\n",
    "    evaluation_strategy=\"epoch\",               # Evaluate the model every epoch\n",
    "                   # Save the model after every epoch\n",
    "    gradient_accumulation_steps=8,             # Number of steps to accumulate gradients\n",
    "    fp16=True,                                 # Enable mixed precision training (if possible)\n",
    "                        # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Initialize Trainer with model and dataset\n",
    "trainer = Trainer(\n",
    "    model=model,                              # The model you want to fine-tune\n",
    "    args=training_args,                       # The training arguments defined above\n",
    "    train_dataset=trainingdata,              # Your training dataset\n",
    "    eval_dataset=evaldata,                # Your evaluation dataset (optional, can be omitted)\n",
    "    compute_metrics=compute_metrics           # Optional: function to compute evaluation metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model after training\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved at ./best_model5\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./best_model5\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"\\nModel saved at {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sathdeepkernel",
   "language": "python",
   "name": "sathdeep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
